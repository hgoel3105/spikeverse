{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63fec226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\hgoel\\appdata\\roaming\\python\\python312\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hgoel\\appdata\\roaming\\python\\python312\\site-packages (0.22.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hgoel\\appdata\\roaming\\python\\python312\\site-packages (3.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement math (from versions: none)\n",
      "ERROR: No matching distribution found for math\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision matplotlib math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb5df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1919f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "Processed 1000/60000 images\n",
      "Processed 2000/60000 images\n",
      "Processed 3000/60000 images\n",
      "Processed 4000/60000 images\n",
      "Processed 5000/60000 images\n",
      "Processed 6000/60000 images\n",
      "Processed 7000/60000 images\n",
      "Processed 8000/60000 images\n",
      "Processed 9000/60000 images\n",
      "Processed 10000/60000 images\n",
      "Processed 11000/60000 images\n",
      "Processed 12000/60000 images\n",
      "Processed 13000/60000 images\n",
      "Processed 14000/60000 images\n",
      "Processed 15000/60000 images\n",
      "Processed 16000/60000 images\n",
      "Processed 17000/60000 images\n",
      "Processed 18000/60000 images\n",
      "Processed 19000/60000 images\n",
      "Processed 20000/60000 images\n",
      "Processed 21000/60000 images\n",
      "Processed 22000/60000 images\n",
      "Processed 23000/60000 images\n",
      "Processed 24000/60000 images\n",
      "Processed 25000/60000 images\n",
      "Processed 26000/60000 images\n",
      "Processed 27000/60000 images\n",
      "Processed 28000/60000 images\n",
      "Processed 29000/60000 images\n",
      "Processed 30000/60000 images\n",
      "Processed 31000/60000 images\n",
      "Processed 32000/60000 images\n",
      "Processed 33000/60000 images\n",
      "Processed 34000/60000 images\n",
      "Processed 35000/60000 images\n",
      "Processed 36000/60000 images\n",
      "Processed 37000/60000 images\n",
      "Processed 38000/60000 images\n",
      "Processed 39000/60000 images\n",
      "Processed 40000/60000 images\n",
      "Processed 41000/60000 images\n",
      "Processed 42000/60000 images\n",
      "Processed 43000/60000 images\n",
      "Processed 44000/60000 images\n",
      "Processed 45000/60000 images\n",
      "Processed 46000/60000 images\n",
      "Processed 47000/60000 images\n",
      "Processed 48000/60000 images\n",
      "Processed 49000/60000 images\n",
      "Processed 50000/60000 images\n",
      "Processed 51000/60000 images\n",
      "Processed 52000/60000 images\n",
      "Processed 53000/60000 images\n",
      "Processed 54000/60000 images\n",
      "Processed 55000/60000 images\n",
      "Processed 56000/60000 images\n",
      "Processed 57000/60000 images\n",
      "Processed 58000/60000 images\n",
      "Processed 59000/60000 images\n",
      "Processed 60000/60000 images\n",
      "Epoch [1/20], Loss: 1.626841, Accuracy: 88.6900%\n",
      "Epoch [2/20], Loss: 1.546896, Accuracy: 93.4583%\n",
      "Epoch [3/20], Loss: 1.533270, Accuracy: 94.3700%\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "total_time = 100  # total time in milliseconds\n",
    "timestep = 1  # time step in milliseconds\n",
    "num_steps = total_time // timestep  # number of time steps\n",
    "max_firing_rate = 200  # maximum firing rate in Hz\n",
    "hidden_size = 100\n",
    "tau = 45.0  # membrane time constant in ms\n",
    "dt = 1.0  # time step in ms\n",
    "v_rest = 0.0  # resting potential\n",
    "v_reset = -0.5  # reset potential after spike\n",
    "v_th = 1.1  # threshold potential for spiking\n",
    "epochs = 20  # number of training epochs\n",
    "\n",
    "train_ds = datasets.MNIST(root='.', train=True, download=True, transform=transforms.ToTensor())\n",
    "print (train_ds[0][0].shape)\n",
    "train_ds = train_ds.data.float() / 255.0\n",
    "\n",
    "def poisson_rate_encoding(train_ds, num_steps, max_firing_rate, num_samples=None):\n",
    "    # If num_samples is None, use the entire dataset\n",
    "    if num_samples is None:\n",
    "        num_samples = train_ds.shape[0]\n",
    "    \n",
    "    # Sample random indices if using a subset, otherwise use all indices\n",
    "    if num_samples < train_ds.shape[0]:\n",
    "        indices = torch.randperm(train_ds.shape[0])[:num_samples]\n",
    "    else:\n",
    "        indices = torch.arange(train_ds.shape[0])\n",
    "    \n",
    "    img_flat = train_ds[0].view(-1)\n",
    "    spike_train = torch.zeros((num_samples, img_flat.shape[0], num_steps))\n",
    "    \n",
    "    # Process images in smaller batches to avoid memory issues\n",
    "    batch_size = 1000  # Process 1000 images at a time\n",
    "    for batch_start in range(0, num_samples, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, num_samples)\n",
    "        batch_indices = indices[batch_start:batch_end]\n",
    "        \n",
    "        for i, idx in enumerate(batch_indices):\n",
    "            img = train_ds[idx]\n",
    "            img_flat = img.view(-1)\n",
    "            firing_rates = img_flat * max_firing_rate\n",
    "            probability = firing_rates / 1000 * timestep\n",
    "            \n",
    "            for t in range(num_steps):\n",
    "                random_values = torch.rand(len(firing_rates))\n",
    "                spikes = (random_values < probability).float()\n",
    "                spike_train[batch_start + i, :, t] = spikes\n",
    "                \n",
    "        print(f\"Processed {batch_end}/{num_samples} images\")\n",
    "            \n",
    "    return spike_train, indices\n",
    "\n",
    "spike_train, indices = poisson_rate_encoding(train_ds, num_steps, max_firing_rate, num_samples=None)\n",
    "\n",
    "\n",
    "# # Visualize spike patterns for several samples (e.g., first 10) and show their labels and images\n",
    "# num_samples_to_plot = 10\n",
    "# fig, axes = plt.subplots(num_samples_to_plot, 2, figsize=(12, 2 * num_samples_to_plot), gridspec_kw={'width_ratios': [3, 1]}, sharex='col')\n",
    "\n",
    "# mnist_targets = datasets.MNIST(root='.', train=True, download=True).targets\n",
    "\n",
    "# for i in range(num_samples_to_plot):\n",
    "#     # Raster plot\n",
    "#     spike_sample = spike_train[i]\n",
    "#     neuron_idx, time_idx = torch.nonzero(spike_sample, as_tuple=True)\n",
    "#     axes[i, 0].scatter(time_idx.numpy(), neuron_idx.numpy(), s=1, color='black')\n",
    "#     label = mnist_targets[indices[i]].item()\n",
    "#     axes[i, 0].set_ylabel('Neuron idx')\n",
    "#     axes[i, 0].set_title(f'Spike raster plot for sample {i} (Label: {label})')\n",
    "#     # Image plot\n",
    "#     img = train_ds[indices[i]].view(28, 28)\n",
    "#     axes[i, 1].imshow(img.numpy(), cmap='gray')\n",
    "#     axes[i, 1].axis('off')\n",
    "#     axes[i, 1].set_title('Input image')\n",
    "\n",
    "# axes[-1, 0].set_xlabel('Time step')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "class SurrogateSpike(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return (input >= 1.0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        surrogate_grad = 1 / (1 + 15 * torch.abs(input - 1.0 )) ** 2\n",
    "        return grad_input * surrogate_grad\n",
    "\n",
    "class LIFLayerSG(nn.Module):\n",
    "    def __init__(self, in_features, out_features, tau=20.0, dt=1.0, v_rest=0.0, v_reset=0.0, v_th=1.0):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(out_features, in_features) * 0.1)\n",
    "        self.decay = math.exp(-dt / tau)\n",
    "        self.v_rest, self.v_reset, self.v_th = v_rest, v_reset, v_th\n",
    "\n",
    "    def forward(self, spikes):\n",
    "        B, F_in, T = spikes.shape\n",
    "        v = torch.zeros(B, self.W.shape[0], device=spikes.device)\n",
    "        spike_history = []\n",
    "\n",
    "        for t in range(T):\n",
    "            I_t = torch.matmul(spikes[:, :, t], self.W.t())\n",
    "            v = (v - self.v_rest) * self.decay + I_t + self.v_rest\n",
    "            z = SurrogateSpike.apply(v - self.v_th)\n",
    "            v = torch.where(z.bool(), torch.full_like(v, self.v_reset), v)\n",
    "            spike_history.append(z)\n",
    "\n",
    "        return torch.stack(spike_history, dim=2)\n",
    "\n",
    "class SNNModelSG(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, **lif_kwargs):\n",
    "        super().__init__()\n",
    "        self.lif1 = LIFLayerSG(input_size, hidden_size, **lif_kwargs)\n",
    "        self.lif2 = LIFLayerSG(hidden_size, output_size, **lif_kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H, W, T = x.shape\n",
    "        x = x.view(B, H * W, T)\n",
    "        s1 = self.lif1(x)\n",
    "        s2 = self.lif2(s1)\n",
    "        return s2.mean(dim=2)  # Average over time\n",
    "\n",
    "# Prepare labels (target)\n",
    "mnist_targets = datasets.MNIST(root='.', train=True, download=True).targets\n",
    "labels = mnist_targets[indices[:]]\n",
    "\n",
    "# Training preparation with mini-batches\n",
    "def train_model(spike_data, labels, model, criterion, optimizer, epochs=10, batch_size=64):\n",
    "    model.train()\n",
    "    dataset_size = spike_data.shape[0]\n",
    "    \n",
    "    # Store metrics for each epoch\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle indices for this epoch\n",
    "        indices = torch.randperm(dataset_size)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        \n",
    "        # Process mini-batches\n",
    "        for i in range(0, dataset_size, batch_size):\n",
    "            # Get mini-batch indices\n",
    "            batch_indices = indices[i:min(i+batch_size, dataset_size)]\n",
    "            \n",
    "            # Get data for this mini-batch\n",
    "            batch_data = spike_data[batch_indices]\n",
    "            batch_labels = labels[batch_indices]\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            running_loss += loss.item() * len(batch_indices)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            running_acc += (predicted == batch_labels).sum().item()\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        epoch_acc = running_acc / dataset_size\n",
    "        \n",
    "        epoch_losses.append(epoch_loss)\n",
    "        epoch_accuracies.append(epoch_acc)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.6f}, Accuracy: {epoch_acc*100:.4f}%\")\n",
    "    \n",
    "    return epoch_losses, epoch_accuracies\n",
    "\n",
    "# Define mini-batch size\n",
    "mini_batch_size = 64\n",
    "\n",
    "# Create the model, criterion and optimizer\n",
    "model = SNNModelSG(input_size=28*28, hidden_size=hidden_size, output_size=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# spike_train: [B, F, T] â†’ reshape to [B, H, W, T]\n",
    "total_samples = spike_train.shape[0]\n",
    "spike_data = spike_train.view(total_samples, 28, 28, -1)\n",
    "\n",
    "# Train with mini-batches\n",
    "losses, accuracies = train_model(spike_data, labels, model, criterion, optimizer, \n",
    "                                epochs=epochs, batch_size=mini_batch_size)\n",
    "\n",
    "# Plot training progress\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracies)\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
